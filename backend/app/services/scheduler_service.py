"""
å®šæ—¶ä»»åŠ¡è°ƒåº¦ç®¡ç†æœåŠ¡
æä¾›å·¥ä½œæµå¼çš„å®šæ—¶ä»»åŠ¡ç®¡ç†ï¼Œæ”¯æŒè‡ªåŠ¨åŒ–å’Œæ‰‹åŠ¨æ§åˆ¶
"""
import logging
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable, Union
from enum import Enum

try:
    from apscheduler.schedulers.background import BackgroundScheduler
    from apscheduler.triggers.interval import IntervalTrigger
    from apscheduler.triggers.cron import CronTrigger
    from apscheduler.events import EVENT_JOB_EXECUTED, EVENT_JOB_ERROR
except ImportError:
    # APScheduleræœªå®‰è£…æ—¶çš„å¤‡ç”¨å¤„ç†
    BackgroundScheduler = None
    IntervalTrigger = None
    CronTrigger = None
    EVENT_JOB_EXECUTED = None
    EVENT_JOB_ERROR = None

from app.config import Config


class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€æšä¸¾"""
    PENDING = "pending"      # ç­‰å¾…æ‰§è¡Œ
    RUNNING = "running"      # æ­£åœ¨æ‰§è¡Œ
    SUCCESS = "success"      # æ‰§è¡ŒæˆåŠŸ
    FAILED = "failed"        # æ‰§è¡Œå¤±è´¥
    DISABLED = "disabled"    # å·²ç¦ç”¨


class WorkflowPhase(Enum):
    """å·¥ä½œæµé˜¶æ®µæšä¸¾"""
    DATA_SYNC = "data_sync"              # æ•°æ®åŒæ­¥é˜¶æ®µ
    CLASSIFICATION = "classification"     # åˆ†ç±»å¤„ç†é˜¶æ®µ
    ANSWER_GENERATION = "answer_generation"  # ç­”æ¡ˆç”Ÿæˆé˜¶æ®µ
    SCORING = "scoring"                  # è¯„åˆ†å¤„ç†é˜¶æ®µ
    REVIEW = "review"                    # å®¡æ ¸é˜¶æ®µ


class SchedulerService:
    """å®šæ—¶ä»»åŠ¡è°ƒåº¦æœåŠ¡"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.scheduler = None
        self.tasks_status: Dict[str, Any] = {}
        self.workflow_status: Dict[str, Any] = {}
        self.execution_history: List[Dict[str, Any]] = []
        self.max_history_size = 200
        self._lock = threading.Lock()
        
        # å·¥ä½œæµé…ç½®
        self.workflow_config = {
            WorkflowPhase.DATA_SYNC: {
                'name': 'æ•°æ®åŒæ­¥',
                'description': 'ä»table1åŒæ­¥æœ€æ–°æ•°æ®åˆ°questionså’Œanswersè¡¨',
                'depends_on': [],
                'auto_next': True
            },
            WorkflowPhase.CLASSIFICATION: {
                'name': 'é—®é¢˜åˆ†ç±»',
                'description': 'è°ƒç”¨åˆ†ç±»APIå¯¹æ–°é—®é¢˜è¿›è¡Œåˆ†ç±»',
                'depends_on': [WorkflowPhase.DATA_SYNC],
                'auto_next': True
            },
            WorkflowPhase.ANSWER_GENERATION: {
                'name': 'ç­”æ¡ˆç”Ÿæˆ',
                'description': 'è°ƒç”¨AI APIç”Ÿæˆé—®é¢˜ç­”æ¡ˆ',
                'depends_on': [WorkflowPhase.CLASSIFICATION],
                'auto_next': True
            },
            WorkflowPhase.SCORING: {
                'name': 'ç­”æ¡ˆè¯„åˆ†',
                'description': 'å¯¹ç”Ÿæˆçš„ç­”æ¡ˆè¿›è¡Œè´¨é‡è¯„åˆ†',
                'depends_on': [WorkflowPhase.ANSWER_GENERATION],
                'auto_next': False
            },
            WorkflowPhase.REVIEW: {
                'name': 'äººå·¥å®¡æ ¸',
                'description': 'äººå·¥å®¡æ ¸å¤„ç†ç»“æœ',
                'depends_on': [WorkflowPhase.SCORING],
                'auto_next': False
            }
        }
        
    def initialize(self, app):
        """åˆå§‹åŒ–è°ƒåº¦å™¨"""
        try:
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨è°ƒåº¦å™¨
            if not app.config.get('SCHEDULER_ENABLED', True):
                self.logger.info("è°ƒåº¦å™¨å·²è¢«é…ç½®ç¦ç”¨ï¼Œè·³è¿‡åˆå§‹åŒ–")
                return

            if BackgroundScheduler is None:
                self.logger.error("APScheduleræœªå®‰è£…ï¼Œæ— æ³•å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨")
                return

            if self.scheduler is not None:
                self.logger.warning("è°ƒåº¦å™¨å·²ç»åˆå§‹åŒ–ï¼Œè·³è¿‡é‡å¤åˆå§‹åŒ–")
                return
            
            self.scheduler = BackgroundScheduler(timezone='Asia/Shanghai')
            
            # æ·»åŠ äº‹ä»¶ç›‘å¬å™¨
            if EVENT_JOB_EXECUTED and EVENT_JOB_ERROR:
                self.scheduler.add_listener(
                    self._job_executed_listener, 
                    EVENT_JOB_EXECUTED
                )
                self.scheduler.add_listener(
                    self._job_error_listener, 
                    EVENT_JOB_ERROR
                )
            
            # å¯åŠ¨è°ƒåº¦å™¨
            self.scheduler.start()
            self.logger.info("å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å¯åŠ¨æˆåŠŸ")
            
            # æ³¨å†Œé»˜è®¤ä»»åŠ¡
            self._register_default_jobs(app)
            
            # åˆå§‹åŒ–å·¥ä½œæµçŠ¶æ€
            self._initialize_workflow_status()
            
            # å¯åŠ¨æ—¶ç«‹å³å¤„ç†å·²æœ‰æ•°æ®
            if app.config.get('AUTO_PROCESS_ON_STARTUP', True):
                self.logger.info("é…ç½®å¯ç”¨å¯åŠ¨æ—¶ç«‹å³å¤„ç†ï¼Œå¼€å§‹å¤„ç†å·²æœ‰æ•°æ®")
                self._startup_immediate_process(app)
            
            # æ³¨å†Œå…³é—­å›è°ƒ (æ³¨é‡Šæ‰é¿å…å¼€å‘æ¨¡å¼ä¸‹è¿‡æ—©å…³é—­)
            # import atexit
            # atexit.register(self.shutdown)
            
        except Exception as e:
            self.logger.error(f"å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    def _startup_immediate_process(self, app):
        """å¯åŠ¨æ—¶ç«‹å³å¤„ç†å·²æœ‰æ•°æ®"""
        # é˜²æ­¢é‡å¤æ‰§è¡Œï¼šæ£€æŸ¥æ˜¯å¦å·²ç»æ‰§è¡Œè¿‡
        if hasattr(app, '_startup_process_executed'):
            self.logger.info("å¯åŠ¨æ—¶å¤„ç†å·²æ‰§è¡Œè¿‡ï¼Œè·³è¿‡é‡å¤æ‰§è¡Œ")
            return
            
        def immediate_process():
            try:
                with app.app_context():
                    # æ ‡è®°å·²æ‰§è¡Œï¼Œé˜²æ­¢é‡å¤
                    app._startup_process_executed = True
                    self.logger.info("ğŸš€ å¼€å§‹å¯åŠ¨æ—¶ç«‹å³å¤„ç†å·²æœ‰æ•°æ®")
                    result = self.execute_full_workflow_with_suspend_check(app)
                    if result.get('success'):
                        self.logger.info(f"âœ… å¯åŠ¨æ—¶æ•°æ®å¤„ç†å®Œæˆ: {result.get('message')}")
                    else:
                        self.logger.error(f"âŒ å¯åŠ¨æ—¶æ•°æ®å¤„ç†å¤±è´¥: {result.get('message')}")
            except Exception as e:
                self.logger.error(f"å¯åŠ¨æ—¶æ•°æ®å¤„ç†å¼‚å¸¸: {str(e)}")
        
        # å»¶è¿Ÿ3ç§’æ‰§è¡Œï¼Œç¡®ä¿åº”ç”¨å®Œå…¨å¯åŠ¨
        import threading
        timer = threading.Timer(3.0, immediate_process)
        timer.start()
    
    def _register_default_jobs(self, app):
        """æ³¨å†Œé»˜è®¤çš„å®šæ—¶ä»»åŠ¡"""
        # è·å–å¯é…ç½®çš„é—´éš”æ—¶é—´
        interval_minutes = app.config.get('WORKFLOW_INTERVAL_MINUTES', 3)
        self.logger.info(f"é…ç½®çš„å·¥ä½œæµé—´éš”æ—¶é—´: {interval_minutes} åˆ†é’Ÿï¼Œç±»å‹: {type(interval_minutes)}")
        
        # ç¡®ä¿é—´éš”æ—¶é—´æ˜¯æ•´æ•°ä¸”å¤§äº0
        if not isinstance(interval_minutes, int) or interval_minutes <= 0:
            interval_minutes = 3
            self.logger.warning(f"å·¥ä½œæµé—´éš”æ—¶é—´æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼: {interval_minutes} åˆ†é’Ÿ")
        
        # ä¸»å·¥ä½œæµä»»åŠ¡ - å¯é…ç½®é—´éš”æ‰§è¡Œ
        self.add_interval_job(
            job_id='configurable_workflow',
            job_name='å¯é…ç½®é—´éš”AIå¤„ç†å·¥ä½œæµ',
            func=lambda: self.execute_full_workflow_with_suspend_check(app),
            minutes=interval_minutes,
            description=f'æ¯{interval_minutes}åˆ†é’Ÿè‡ªåŠ¨æ‰§è¡Œå®Œæ•´çš„AIæ•°æ®å¤„ç†å·¥ä½œæµï¼ˆæ”¯æŒæ— æ•°æ®æŒ‚èµ·ï¼‰',
            enabled=True
        )
        
        # æ•°æ®åŒæ­¥ä»»åŠ¡ - å¯ç‹¬ç«‹æ‰§è¡Œ
        self.add_interval_job(
            job_id='frequent_data_sync',
            job_name='é¢‘ç¹æ•°æ®åŒæ­¥',
            func=lambda: self.execute_workflow_phase(app, WorkflowPhase.DATA_SYNC),
            minutes=interval_minutes,
            description=f'æ¯{interval_minutes}åˆ†é’Ÿè‡ªåŠ¨åŒæ­¥æ•°æ®ï¼ˆå¯ç‹¬ç«‹æ‰§è¡Œï¼‰',
            enabled=False  # é»˜è®¤ç¦ç”¨ï¼Œç”±ä¸»å·¥ä½œæµæ§åˆ¶
        )
    
    def _initialize_workflow_status(self):
        """åˆå§‹åŒ–å·¥ä½œæµçŠ¶æ€"""
        with self._lock:
            for phase in WorkflowPhase:
                self.workflow_status[phase.value] = {
                    'phase': phase.value,
                    'name': self.workflow_config[phase]['name'],
                    'description': self.workflow_config[phase]['description'],
                    'status': TaskStatus.PENDING.value,
                    'last_execution': None,
                    'execution_count': 0,
                    'success_count': 0,
                    'error_count': 0,
                    'current_batch_id': None,
                    'progress': 0,
                    'message': '',
                    'can_execute': self._can_execute_phase(phase)
                }
    
    def execute_full_workflow(self, app) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´å·¥ä½œæµ"""
        workflow_id = f"workflow_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        try:
            self.logger.info(f"å¼€å§‹æ‰§è¡Œå®Œæ•´å·¥ä½œæµ: {workflow_id}")
            
            results = {}
            
            # æŒ‰é¡ºåºæ‰§è¡Œå„ä¸ªé˜¶æ®µ
            phases = [
                WorkflowPhase.DATA_SYNC,
                WorkflowPhase.CLASSIFICATION,
                WorkflowPhase.ANSWER_GENERATION,
                WorkflowPhase.SCORING
            ]
            
            for phase in phases:
                self.logger.info(f"æ‰§è¡Œå·¥ä½œæµé˜¶æ®µ: {phase.value}")
                
                result = self.execute_workflow_phase(app, phase, workflow_id)
                results[phase.value] = result
                
                if not result.get('success', False):
                    self.logger.error(f"å·¥ä½œæµé˜¶æ®µå¤±è´¥: {phase.value}, åœæ­¢åç»­æ‰§è¡Œ")
                    break
                
                # æ£€æŸ¥æ˜¯å¦è‡ªåŠ¨è¿›å…¥ä¸‹ä¸€é˜¶æ®µ
                if not self.workflow_config[phase]['auto_next']:
                    self.logger.info(f"é˜¶æ®µ {phase.value} ä¸è‡ªåŠ¨è¿›å…¥ä¸‹ä¸€é˜¶æ®µï¼Œå·¥ä½œæµæš‚åœ")
                    break
            
            # è®°å½•å·¥ä½œæµæ‰§è¡Œç»“æœ
            self._record_workflow_execution(workflow_id, results)
            
            return {
                'success': True,
                'workflow_id': workflow_id,
                'message': 'å·¥ä½œæµæ‰§è¡Œå®Œæˆ',
                'results': results
            }
            
        except Exception as e:
            error_msg = f"å·¥ä½œæµæ‰§è¡Œå¼‚å¸¸: {str(e)}"
            self.logger.error(error_msg)
            return {
                'success': False,
                'workflow_id': workflow_id,
                'message': error_msg,
                'results': {}
            }
    
    def execute_full_workflow_with_suspend_check(self, app) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´å·¥ä½œæµï¼ˆå¸¦æ— æ•°æ®æŒ‚èµ·æ£€æŸ¥ï¼‰"""
        workflow_id = f"workflow_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        try:
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨æ•°æ®æ£€æµ‹
            if not app.config.get('DATA_CHECK_ENABLED', True):
                return self.execute_full_workflow(app)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯å¤„ç†çš„æ•°æ®
            has_data_to_process = self._check_if_has_data_to_process(app)
            
            if not has_data_to_process:
                if app.config.get('AUTO_SUSPEND_WHEN_NO_DATA', True):
                    self.logger.info("ğŸ’¤ æ²¡æœ‰æ£€æµ‹åˆ°å¯å¤„ç†çš„æ•°æ®ï¼Œå·¥ä½œæµæŒ‚èµ·ç­‰å¾…")
                    return {
                        'success': True,
                        'workflow_id': workflow_id,
                        'message': 'æ²¡æœ‰å¯å¤„ç†çš„æ•°æ®ï¼Œå·¥ä½œæµæŒ‚èµ·ç­‰å¾…',
                        'suspended': True,
                        'results': {}
                    }
            
            self.logger.info(f"æ£€æµ‹åˆ°å¯å¤„ç†æ•°æ®ï¼Œå¼€å§‹æ‰§è¡Œå®Œæ•´å·¥ä½œæµ: {workflow_id}")
            
            # æ‰§è¡Œæ­£å¸¸çš„å·¥ä½œæµ
            result = self.execute_full_workflow(app)
            result['suspended'] = False
            return result
            
        except Exception as e:
            error_msg = f"å¸¦æŒ‚èµ·æ£€æŸ¥çš„å·¥ä½œæµæ‰§è¡Œå¼‚å¸¸: {str(e)}"
            self.logger.error(error_msg)
            return {
                'success': False,
                'workflow_id': workflow_id,
                'message': error_msg,
                'suspended': False,
                'results': {}
            }
    
    def _check_if_has_data_to_process(self, app) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å¯å¤„ç†çš„æ•°æ®"""
        try:
            with app.app_context():
                from app.models.question import Question
                from app.models.answer import Answer
                from app.utils.database import db
                from sqlalchemy import func, and_, or_
                
                min_batch_size = app.config.get('MIN_BATCH_SIZE', 1)
                
                # æ£€æŸ¥æ•°æ®åŒæ­¥é˜¶æ®µï¼šæ˜¯å¦æœ‰æ–°æ•°æ®éœ€è¦åŒæ­¥ï¼ˆé™åˆ¶æœ¬å‘¨æ•°æ®ï¼Œé¿å…é‡å¤åŒæ­¥ï¼‰
                from app.services.sync_service import sync_service
                from datetime import datetime, timedelta

                # è·å–æœ¬å‘¨å¼€å§‹æ—¶é—´
                today = datetime.utcnow()
                days_since_monday = today.weekday()
                week_start = today - timedelta(days=days_since_monday)
                week_start = week_start.replace(hour=0, minute=0, second=0, microsecond=0)

                from sqlalchemy import text
                # æ£€æŸ¥æœ¬å‘¨æœªåŒæ­¥çš„æ•°æ®é‡ï¼ˆæ’é™¤å·²å­˜åœ¨çš„business_idï¼‰
                new_data_query = text("""
                    SELECT COUNT(*) FROM table1 t1
                    WHERE t1.query IS NOT NULL
                    AND t1.query != ''
                    AND TRIM(t1.query) != ''
                    AND t1.sendmessagetime >= :week_start
                    AND NOT EXISTS (
                        SELECT 1 FROM questions q
                        WHERE q.business_id = MD5(CONCAT(
                            t1.pageid,
                            COALESCE(to_char(t1.sendmessagetime, 'YYYY-MM-DD"T"HH24:MI:SS.US'), ''),
                            t1.query
                        ))
                    )
                """)
                new_data_count = db.session.execute(new_data_query, {
                    'week_start': week_start
                }).scalar()
                
                if new_data_count >= min_batch_size:
                    self.logger.info(f"ğŸ” æ£€æµ‹åˆ° {new_data_count} æ¡æ–°æ•°æ®éœ€è¦åŒæ­¥")
                    return True
                
                # æ£€æŸ¥åˆ†ç±»é˜¶æ®µï¼šæ˜¯å¦æœ‰æœªåˆ†ç±»çš„é—®é¢˜
                unclassified_count = db.session.query(Question).filter(
                    or_(Question.classification.is_(None), Question.classification == '')
                ).count()
                
                if unclassified_count >= min_batch_size:
                    self.logger.info(f"ğŸ” æ£€æµ‹åˆ° {unclassified_count} æ¡é—®é¢˜éœ€è¦åˆ†ç±»")
                    return True
                
                # æ£€æŸ¥ç­”æ¡ˆç”Ÿæˆé˜¶æ®µï¼šæ˜¯å¦æœ‰å·²åˆ†ç±»ä½†æœªç”Ÿæˆç­”æ¡ˆçš„é—®é¢˜
                # æŸ¥æ‰¾æœ‰åˆ†ç±»ä½†ç¼ºå°‘è±†åŒ…æˆ–å°å¤©ç­”æ¡ˆçš„é—®é¢˜
                questions_needing_answers = db.session.query(Question).filter(
                    and_(
                        Question.classification.isnot(None),
                        Question.classification != '',
                        Question.processing_status.in_(['classified', 'generating', 'answers_generated'])
                    )
                ).count()

                if questions_needing_answers >= min_batch_size:
                    self.logger.info(f"ğŸ” æ£€æµ‹åˆ° {questions_needing_answers} æ¡é—®é¢˜éœ€è¦ç”Ÿæˆç­”æ¡ˆ")
                    return True

                # æ£€æŸ¥è¯„åˆ†é˜¶æ®µï¼šæ˜¯å¦æœ‰æœªè¯„åˆ†çš„ç­”æ¡ˆ
                # ä¼˜åŒ–ï¼šæ£€æŸ¥æœ‰å®Œæ•´ç­”æ¡ˆä½†æœªå®Œæˆè¯„åˆ†çš„é—®é¢˜
                unscored_questions = db.session.query(Question).filter(
                    and_(
                        Question.processing_status.in_(['answers_generated', 'scoring']),
                        Question.classification.isnot(None),
                        Question.classification != ''
                    )
                ).count()

                if unscored_questions >= min_batch_size:
                    self.logger.info(f"ğŸ” æ£€æµ‹åˆ° {unscored_questions} æ¡é—®é¢˜éœ€è¦è¯„åˆ†")
                    return True
                
                self.logger.info("ğŸ” æ²¡æœ‰æ£€æµ‹åˆ°è¶³å¤Ÿçš„å¾…å¤„ç†æ•°æ®")
                return False
                
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥å¾…å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            # å‡ºé”™æ—¶é»˜è®¤è¿”å›Trueï¼Œé¿å…é˜»å¡æ­£å¸¸æµç¨‹
            return True
    
    def execute_workflow_phase(
        self, 
        app, 
        phase: WorkflowPhase, 
        workflow_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥ä½œæµçš„ç‰¹å®šé˜¶æ®µ"""
        
        if workflow_id is None:
            workflow_id = f"manual_{phase.value}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # æ£€æŸ¥ä¾èµ–
        if not self._check_phase_dependencies(phase):
            return {
                'success': False,
                'message': f'é˜¶æ®µ {phase.value} çš„ä¾èµ–æ¡ä»¶æœªæ»¡è¶³',
                'phase': phase.value
            }
        
        # æ›´æ–°é˜¶æ®µçŠ¶æ€
        self._update_phase_status(phase, TaskStatus.RUNNING, workflow_id)
        
        try:
            with app.app_context():
                if phase == WorkflowPhase.DATA_SYNC:
                    result = self._execute_data_sync_phase(app, workflow_id)
                elif phase == WorkflowPhase.CLASSIFICATION:
                    result = self._execute_classification_phase(app, workflow_id)
                elif phase == WorkflowPhase.ANSWER_GENERATION:
                    result = self._execute_answer_generation_phase(app, workflow_id)
                elif phase == WorkflowPhase.SCORING:
                    result = self._execute_scoring_phase(app, workflow_id)
                elif phase == WorkflowPhase.REVIEW:
                    result = self._execute_review_phase(app, workflow_id)
                else:
                    result = {'success': False, 'message': f'æœªçŸ¥é˜¶æ®µ: {phase.value}'}
                
                # æ›´æ–°é˜¶æ®µçŠ¶æ€
                status = TaskStatus.SUCCESS if result.get('success', False) else TaskStatus.FAILED
                self._update_phase_status(
                    phase, 
                    status, 
                    workflow_id, 
                    message=result.get('message', ''),
                    progress=100 if status == TaskStatus.SUCCESS else 0
                )
                
                return result
                
        except Exception as e:
            error_msg = f"é˜¶æ®µ {phase.value} æ‰§è¡Œå¼‚å¸¸: {str(e)}"
            self.logger.error(error_msg)
            
            self._update_phase_status(
                phase, 
                TaskStatus.FAILED, 
                workflow_id, 
                message=error_msg
            )
            
            return {
                'success': False,
                'message': error_msg,
                'phase': phase.value
            }
    
    def _execute_data_sync_phase(self, app, workflow_id: str) -> Dict[str, Any]:
        """æ‰§è¡Œæ•°æ®åŒæ­¥é˜¶æ®µ"""
        from app.services.sync_service import sync_service
        
        self.logger.info(f"å¼€å§‹æ‰§è¡Œæ•°æ®åŒæ­¥é˜¶æ®µ [workflow: {workflow_id}]")
        
        try:
            result = sync_service.perform_sync()
            
            if result['success']:
                self.logger.info(f"æ•°æ®åŒæ­¥é˜¶æ®µå®Œæˆ: {result['message']}")
            else:
                self.logger.error(f"æ•°æ®åŒæ­¥é˜¶æ®µå¤±è´¥: {result['message']}")
                
            return result
            
        except Exception as e:
            error_msg = f"æ•°æ®åŒæ­¥é˜¶æ®µå¼‚å¸¸: {str(e)}"
            self.logger.error(error_msg)
            return {'success': False, 'message': error_msg}
    
    def _execute_classification_phase(self, app, workflow_id: str) -> Dict[str, Any]:
        """æ‰§è¡Œåˆ†ç±»å¤„ç†é˜¶æ®µ"""
        self.logger.info(f"å¼€å§‹æ‰§è¡Œåˆ†ç±»å¤„ç†é˜¶æ®µ [workflow: {workflow_id}]")
        
        try:
            # TODO: åˆ›å»ºAIå¤„ç†æœåŠ¡åå–æ¶ˆæ³¨é‡Š
            # from app.services.ai_processing_service import ai_processing_service
            # result = ai_processing_service.process_classification_batch()
            
            # ä¸´æ—¶è¿”å›æˆåŠŸç»“æœ
            result = {
                'success': True, 
                'message': 'åˆ†ç±»å¤„ç†é˜¶æ®µå®Œæˆï¼ˆå¾…å®ç°å…·ä½“é€»è¾‘ï¼‰',
                'processed_count': 0
            }
            return result
            
        except Exception as e:
            error_msg = f"åˆ†ç±»å¤„ç†é˜¶æ®µå¼‚å¸¸: {str(e)}"
            self.logger.error(error_msg)
            return {'success': False, 'message': error_msg}
    
    def _execute_answer_generation_phase(self, app, workflow_id: str) -> Dict[str, Any]:
        """æ‰§è¡Œç­”æ¡ˆç”Ÿæˆé˜¶æ®µï¼ˆæ”¯æŒæ‰‹åŠ¨æ¨¡å¼å’ŒAPIæ¨¡å¼åˆ‡æ¢ï¼‰"""
        self.logger.info(f"å¼€å§‹æ‰§è¡Œç­”æ¡ˆç”Ÿæˆé˜¶æ®µ [workflow: {workflow_id}]")

        try:
            with app.app_context():
                from app.services.system_config_service import SystemConfigService
                from app.services.answer_generation_service import AnswerGenerationService

                # è·å–ç­”æ¡ˆç”Ÿæˆæ¨¡å¼é…ç½®
                config_service = SystemConfigService()
                answer_generation_mode = config_service.get_config('workflow.answer_generation_mode', 'manual')

                self.logger.info(f"å½“å‰ç­”æ¡ˆç”Ÿæˆæ¨¡å¼: {answer_generation_mode}")

                if answer_generation_mode == 'manual':
                    # æ‰‹åŠ¨æ¨¡å¼ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å¾…å¯¼å‡ºçš„é—®é¢˜
                    answer_service = AnswerGenerationService()
                    pending_count = answer_service.get_export_questions_count()

                    if pending_count > 0:
                        return {
                            'success': True,
                            'message': f'æ‰‹åŠ¨æ¨¡å¼ï¼šæœ‰{pending_count}ä¸ªé—®é¢˜å¾…å¯¼å‡ºExcelè¿›è¡Œç­”æ¡ˆç”Ÿæˆ',
                            'pending_count': pending_count,
                            'mode': 'manual',
                            'action_required': 'export_excel'
                        }
                    else:
                        return {
                            'success': True,
                            'message': 'æ‰‹åŠ¨æ¨¡å¼ï¼šæ— å¾…å¤„ç†é—®é¢˜',
                            'pending_count': 0,
                            'mode': 'manual',
                            'action_required': 'none'
                        }

                elif answer_generation_mode == 'api':
                    # APIæ¨¡å¼ï¼šè°ƒç”¨åŸæœ‰çš„APIç”Ÿæˆé€»è¾‘
                    from app.services.ai_processing_service import ai_processing_service
                    result = ai_processing_service.process_answer_generation_batch()
                    result['mode'] = 'api'
                    return result

                else:
                    return {
                        'success': False,
                        'message': f'æœªçŸ¥çš„ç­”æ¡ˆç”Ÿæˆæ¨¡å¼: {answer_generation_mode}',
                        'mode': answer_generation_mode
                    }

        except Exception as e:
            error_msg = f"ç­”æ¡ˆç”Ÿæˆé˜¶æ®µå¼‚å¸¸: {str(e)}"
            self.logger.error(error_msg)
            return {'success': False, 'message': error_msg}
    
    def _execute_scoring_phase(self, app, workflow_id: str) -> Dict[str, Any]:
        """æ‰§è¡Œè¯„åˆ†å¤„ç†é˜¶æ®µ"""
        self.logger.info(f"å¼€å§‹æ‰§è¡Œè¯„åˆ†å¤„ç†é˜¶æ®µ [workflow: {workflow_id}]")
        
        try:
            from app.services.ai_processing_service import AIProcessingService
            ai_service = AIProcessingService()
            result = ai_service.process_scoring_batch()
            return result
            
        except Exception as e:
            error_msg = f"è¯„åˆ†å¤„ç†é˜¶æ®µå¼‚å¸¸: {str(e)}"
            self.logger.error(error_msg)
            return {'success': False, 'message': error_msg}
    
    def _execute_review_phase(self, app, workflow_id: str) -> Dict[str, Any]:
        """æ‰§è¡Œå®¡æ ¸é˜¶æ®µï¼ˆé€šå¸¸æ˜¯äººå·¥æ“ä½œï¼‰"""
        self.logger.info(f"å¼€å§‹æ‰§è¡Œå®¡æ ¸é˜¶æ®µ [workflow: {workflow_id}]")
        
        # å®¡æ ¸é˜¶æ®µé€šå¸¸æ˜¯äººå·¥æ“ä½œï¼Œè¿™é‡Œåªæ˜¯æ ‡è®°ä¸ºå¯å®¡æ ¸çŠ¶æ€
        return {
            'success': True,
            'message': 'å®¡æ ¸é˜¶æ®µå·²å‡†å¤‡å°±ç»ªï¼Œç­‰å¾…äººå·¥æ“ä½œ',
            'requires_manual_action': True
        }
    
    def _check_phase_dependencies(self, phase: WorkflowPhase) -> bool:
        """æ£€æŸ¥é˜¶æ®µä¾èµ–æ˜¯å¦æ»¡è¶³"""
        dependencies = self.workflow_config[phase]['depends_on']
        
        for dep_phase in dependencies:
            if dep_phase.value not in self.workflow_status:
                return False
            
            dep_status = self.workflow_status[dep_phase.value]['status']
            if dep_status != TaskStatus.SUCCESS.value:
                return False
        
        return True
    
    def _can_execute_phase(self, phase: WorkflowPhase) -> bool:
        """æ£€æŸ¥é˜¶æ®µæ˜¯å¦å¯ä»¥æ‰§è¡Œ"""
        return self._check_phase_dependencies(phase)
    
    def _update_phase_status(
        self, 
        phase: WorkflowPhase, 
        status: TaskStatus,
        workflow_id: Optional[str] = None,
        message: str = '',
        progress: int = 0
    ):
        """æ›´æ–°é˜¶æ®µçŠ¶æ€"""
        with self._lock:
            if phase.value in self.workflow_status:
                self.workflow_status[phase.value].update({
                    'status': status.value,
                    'last_execution': datetime.now().isoformat(),
                    'current_batch_id': workflow_id,
                    'message': message,
                    'progress': progress
                })
                
                if status == TaskStatus.RUNNING:
                    self.workflow_status[phase.value]['execution_count'] += 1
                elif status == TaskStatus.SUCCESS:
                    self.workflow_status[phase.value]['success_count'] += 1
                elif status == TaskStatus.FAILED:
                    self.workflow_status[phase.value]['error_count'] += 1
                
                # æ›´æ–°æ‰€æœ‰é˜¶æ®µçš„å¯æ‰§è¡ŒçŠ¶æ€
                for p in WorkflowPhase:
                    self.workflow_status[p.value]['can_execute'] = self._can_execute_phase(p)
    
    def _record_workflow_execution(self, workflow_id: str, results: Dict):
        """è®°å½•å·¥ä½œæµæ‰§è¡Œç»“æœ"""
        record = {
            'workflow_id': workflow_id,
            'execution_time': datetime.now().isoformat(),
            'results': results,
            'success': all(r.get('success', False) for r in results.values())
        }
        
        with self._lock:
            self.execution_history.append(record)
            
            # ä¿æŒå†å²è®°å½•æ•°é‡é™åˆ¶
            if len(self.execution_history) > self.max_history_size:
                self.execution_history = self.execution_history[-self.max_history_size:]
    
    def add_cron_job(
        self,
        job_id: str,
        job_name: str,
        func: Callable,
        minute: int = 0,
        hour: int = 0,
        day: Optional[int] = None,
        month: Optional[int] = None,
        day_of_week: Optional[int] = None,
        description: str = "",
        enabled: bool = True
    ) -> bool:
        """æ·»åŠ å®šæ—¶æ‰§è¡Œçš„ä»»åŠ¡"""
        try:
            if not enabled:
                self.logger.info(f"ä»»åŠ¡ {job_name} è¢«ç¦ç”¨ï¼Œè·³è¿‡æ·»åŠ ")
                return False
            
            if CronTrigger is None:
                self.logger.error("APScheduleræœªå®‰è£…ï¼Œæ— æ³•æ·»åŠ å®šæ—¶ä»»åŠ¡")
                return False
                
            trigger = CronTrigger(
                minute=minute,
                hour=hour,
                day=day,
                month=month,
                day_of_week=day_of_week,
                timezone='Asia/Shanghai'
            )
            
            if self.scheduler is None:
                self.logger.error("è°ƒåº¦å™¨æœªåˆå§‹åŒ–")
                return False
                
            self.scheduler.add_job(
                func=func,
                trigger=trigger,
                id=job_id,
                name=job_name,
                replace_existing=True
            )
            
            # è®°å½•ä»»åŠ¡çŠ¶æ€
            with self._lock:
                self.tasks_status[job_id] = {
                    'name': job_name,
                    'type': 'cron',
                    'description': description,
                    'enabled': enabled,
                    'created_at': datetime.now().isoformat(),
                    'last_execution': None,
                    'execution_count': 0,
                    'success_count': 0,
                    'error_count': 0,
                    'config': {
                        'minute': minute,
                        'hour': hour,
                        'day': day,
                        'month': month,
                        'day_of_week': day_of_week
                    }
                }
            
            self.logger.info(f"æ·»åŠ å®šæ—¶ä»»åŠ¡æˆåŠŸ: {job_name} (cron: {hour:02d}:{minute:02d})")
            return True
            
        except Exception as e:
            self.logger.error(f"æ·»åŠ å®šæ—¶ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False
    
    def add_interval_job(
        self,
        job_id: str,
        job_name: str,
        func: Callable,
        seconds: Optional[int] = None,
        minutes: Optional[int] = None,
        hours: Optional[int] = None,
        days: Optional[int] = None,
        description: str = "",
        enabled: bool = True
    ) -> bool:
        """æ·»åŠ é—´éš”æ‰§è¡Œçš„ä»»åŠ¡"""
        try:
            if not enabled:
                self.logger.info(f"ä»»åŠ¡ {job_name} è¢«ç¦ç”¨ï¼Œè·³è¿‡æ·»åŠ ")
                return False
            
            if IntervalTrigger is None:
                self.logger.error("APScheduleræœªå®‰è£…ï¼Œæ— æ³•æ·»åŠ é—´éš”ä»»åŠ¡")
                return False
                
            # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ‰€æœ‰å‚æ•°å€¼
            self.logger.info(f"æ·»åŠ ä»»åŠ¡ {job_name} - seconds={seconds}, minutes={minutes}, hours={hours}, days={days}")
            
            # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªæ—¶é—´å‚æ•°ä¸ä¸ºNone
            if all(param is None for param in [seconds, minutes, hours, days]):
                self.logger.error(f"æ·»åŠ ä»»åŠ¡å¤±è´¥ï¼šæ‰€æœ‰æ—¶é—´å‚æ•°éƒ½ä¸ºNone - {job_name}")
                return False
                
            # åˆ›å»º IntervalTrigger æ—¶åªä¼ é€’é None çš„å‚æ•°
            trigger_kwargs = {'timezone': 'Asia/Shanghai'}
            if seconds is not None:
                trigger_kwargs['seconds'] = seconds
            if minutes is not None:
                trigger_kwargs['minutes'] = minutes
            if hours is not None:
                trigger_kwargs['hours'] = hours
            if days is not None:
                trigger_kwargs['days'] = days
                
            trigger = IntervalTrigger(**trigger_kwargs)
            
            if self.scheduler is None:
                self.logger.error("è°ƒåº¦å™¨æœªåˆå§‹åŒ–")
                return False
                
            self.scheduler.add_job(
                func=func,
                trigger=trigger,
                id=job_id,
                name=job_name,
                replace_existing=True
            )
            
            # è®°å½•ä»»åŠ¡çŠ¶æ€
            with self._lock:
                self.tasks_status[job_id] = {
                    'name': job_name,
                    'type': 'interval',
                    'description': description,
                    'enabled': enabled,
                    'created_at': datetime.now().isoformat(),
                    'last_execution': None,
                    'execution_count': 0,
                    'success_count': 0,
                    'error_count': 0,
                    'config': {
                        'seconds': seconds,
                        'minutes': minutes,
                        'hours': hours,
                        'days': days
                    }
                }
            
            interval_str = ""
            if days:
                interval_str += f"{days}å¤©"
            if hours:
                interval_str += f"{hours}å°æ—¶"
            if minutes:
                interval_str += f"{minutes}åˆ†é’Ÿ"
            if seconds:
                interval_str += f"{seconds}ç§’"
            
            self.logger.info(f"æ·»åŠ é—´éš”ä»»åŠ¡æˆåŠŸ: {job_name} (é—´éš”: {interval_str})")
            return True
            
        except Exception as e:
            self.logger.error(f"æ·»åŠ é—´éš”ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False
    
    def pause_job(self, job_id: str) -> bool:
        """æš‚åœå®šæ—¶ä»»åŠ¡"""
        try:
            if self.scheduler is None:
                return False
                
            self.scheduler.pause_job(job_id)
            
            with self._lock:
                if job_id in self.tasks_status:
                    self.tasks_status[job_id]['enabled'] = False
            
            self.logger.info(f"æš‚åœå®šæ—¶ä»»åŠ¡æˆåŠŸ: {job_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"æš‚åœå®šæ—¶ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False
    
    def resume_job(self, job_id: str) -> bool:
        """æ¢å¤å®šæ—¶ä»»åŠ¡"""
        try:
            if self.scheduler is None:
                return False

            self.scheduler.resume_job(job_id)

            with self._lock:
                if job_id in self.tasks_status:
                    self.tasks_status[job_id]['enabled'] = True

            self.logger.info(f"æ¢å¤å®šæ—¶ä»»åŠ¡æˆåŠŸ: {job_id}")
            return True

        except Exception as e:
            self.logger.error(f"æ¢å¤å®šæ—¶ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False

    def trigger_job(self, job_id: str) -> bool:
        """ç«‹å³æ‰§è¡Œå®šæ—¶ä»»åŠ¡"""
        try:
            if self.scheduler is None:
                return False

            # è·å–ä»»åŠ¡å¹¶ç«‹å³æ‰§è¡Œ
            job = self.scheduler.get_job(job_id)
            if job is None:
                self.logger.error(f"ä»»åŠ¡ä¸å­˜åœ¨: {job_id}")
                return False

            # ç«‹å³æ‰§è¡Œä»»åŠ¡
            job.modify(next_run_time=datetime.now())

            self.logger.info(f"ç«‹å³æ‰§è¡Œå®šæ—¶ä»»åŠ¡æˆåŠŸ: {job_id}")
            return True

        except Exception as e:
            self.logger.error(f"ç«‹å³æ‰§è¡Œå®šæ—¶ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False
    
    def get_scheduler_status(self) -> Dict[str, Any]:
        """è·å–è°ƒåº¦å™¨å®Œæ•´çŠ¶æ€"""
        scheduler_jobs = []
        if self.scheduler:
            for job in self.scheduler.get_jobs():
                scheduler_jobs.append({
                    'id': job.id,
                    'name': job.name,
                    'next_run_time': job.next_run_time.isoformat() if job.next_run_time else None,
                    'trigger': str(job.trigger)
                })
        
        with self._lock:
            return {
                'scheduler_running': self.scheduler.running if self.scheduler else False,
                'current_time': datetime.now().isoformat(),
                'scheduled_jobs': {
                    'count': len(self.tasks_status),
                    'jobs': dict(self.tasks_status),
                    'scheduler_jobs': scheduler_jobs
                },
                'workflow': {
                    'phases': dict(self.workflow_status),
                    'execution_history': self.execution_history[-10:]  # æœ€è¿‘10æ¡è®°å½•
                }
            }
    
    def get_workflow_status(self) -> Dict[str, Any]:
        """è·å–å·¥ä½œæµçŠ¶æ€"""
        with self._lock:
            return {
                'phases': dict(self.workflow_status),
                'execution_history': self.execution_history[-20:]
            }
    
    def _job_executed_listener(self, event):
        """ä»»åŠ¡æ‰§è¡ŒæˆåŠŸç›‘å¬å™¨"""
        job_id = event.job_id
        
        with self._lock:
            if job_id in self.tasks_status:
                self.tasks_status[job_id]['last_execution'] = datetime.now().isoformat()
                self.tasks_status[job_id]['execution_count'] += 1
                self.tasks_status[job_id]['success_count'] += 1
    
    def _job_error_listener(self, event):
        """ä»»åŠ¡æ‰§è¡Œå¤±è´¥ç›‘å¬å™¨"""
        job_id = event.job_id
        
        with self._lock:
            if job_id in self.tasks_status:
                self.tasks_status[job_id]['last_execution'] = datetime.now().isoformat()
                self.tasks_status[job_id]['execution_count'] += 1
                self.tasks_status[job_id]['error_count'] += 1
        
        self.logger.error(f"å®šæ—¶ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {job_id}, é”™è¯¯: {event.exception}")
    
    def shutdown(self):
        """å…³é—­è°ƒåº¦å™¨"""
        if self.scheduler and self.scheduler.running:
            self.scheduler.shutdown(wait=False)
            self.logger.info("å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å…³é—­")


# åˆ›å»ºå…¨å±€è°ƒåº¦å™¨å®ä¾‹
scheduler_service = SchedulerService() 