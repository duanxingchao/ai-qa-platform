#!/usr/bin/env python3
"""
Mockè¯„åˆ†APIæœåŠ¡å™¨
æŒ‰ç…§ç”¨æˆ·æŒ‡å®šçš„æ ¼å¼æ¨¡æ‹Ÿè¯„åˆ†APIï¼Œæ”¯æŒå¤šæ¨¡åž‹è¯„åˆ†

å¯åŠ¨æ–¹å¼:
python mock_score_api.py --port 8004
"""
import random
import time
import json
import argparse
import socket
from datetime import datetime
from flask import Flask, request, jsonify

app = Flask(__name__)

# è¯„åˆ†ç»´åº¦å®šä¹‰
SCORING_DIMENSIONS = {
    'accuracy': 'å‡†ç¡®æ€§',
    'completeness': 'å®Œæ•´æ€§', 
    'clarity': 'æ¸…æ™°åº¦',
    'relevance': 'ç›¸å…³æ€§',
    'helpfulness': 'æœ‰ç”¨æ€§'
}

# æ¨¡åž‹åç§°æ˜ å°„
MODEL_NAMES = {
    'our_ai': 'åŽŸå§‹æ¨¡åž‹',
    'doubao': 'è±†åŒ…æ¨¡åž‹',
    'xiaotian': 'å°å¤©æ¨¡åž‹'
}

def analyze_answer_quality(question, answer, classification, model_type):
    """åˆ†æžç­”æ¡ˆè´¨é‡å¹¶ç”Ÿæˆè¯„åˆ†"""
    if not answer or not answer.strip():
        # ç©ºç­”æ¡ˆç»™ä½Žåˆ†
        scores = {dim: random.randint(1, 2) for dim in SCORING_DIMENSIONS.keys()}
        reason = "ç­”æ¡ˆä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œæ— æ³•æä¾›æœ‰æ•ˆä¿¡æ¯"
        return scores, reason
    
    # åŸºç¡€è¯„åˆ†ï¼ˆæ ¹æ®æ¨¡åž‹ç±»åž‹è®¾ç½®ä¸åŒåŸºå‡†ï¼‰
    if model_type == 'our_ai':
        # åŽŸå§‹æ¨¡åž‹ç¨å¾®ä½Žä¸€äº›
        base_range = (2, 4)
    elif model_type == 'doubao':
        # è±†åŒ…æ¨¡åž‹ç¨å¾®é«˜ä¸€äº›
        base_range = (3, 5)
    else:  # xiaotian
        # å°å¤©æ¨¡åž‹ä¸­ç­‰æ°´å¹³
        base_range = (2, 4)
    
    scores = {}
    
    # åˆ†æžç­”æ¡ˆå†…å®¹
    answer_lower = answer.lower()
    question_lower = question.lower() if question else ""
    
    # å‡†ç¡®æ€§è¯„åˆ†
    accuracy_score = random.randint(*base_range)
    if any(word in answer_lower for word in ['å‡†ç¡®', 'æ­£ç¡®', 'äº‹å®ž', 'æ•°æ®']):
        accuracy_score = min(5, accuracy_score + 1)
    if any(word in answer_lower for word in ['é”™è¯¯', 'ä¸å¯¹', 'ä¸ç¡®å®š']):
        accuracy_score = max(1, accuracy_score - 1)
    scores['accuracy'] = accuracy_score
    
    # å®Œæ•´æ€§è¯„åˆ†
    completeness_score = random.randint(*base_range)
    if len(answer) > 200:
        completeness_score = min(5, completeness_score + 1)
    if any(word in answer for word in ['é¦–å…ˆ', 'å…¶æ¬¡', 'æœ€åŽ', 'æ€»ç»“']):
        completeness_score = min(5, completeness_score + 1)
    scores['completeness'] = completeness_score
    
    # æ¸…æ™°åº¦è¯„åˆ†
    clarity_score = random.randint(*base_range)
    if any(word in answer for word in ['æ¸…æ¥š', 'æ˜Žç¡®', 'ç®€å•', 'æ˜“æ‡‚']):
        clarity_score = min(5, clarity_score + 1)
    scores['clarity'] = clarity_score
    
    # ç›¸å…³æ€§è¯„åˆ† 
    relevance_score = random.randint(*base_range)
    if question and classification:
        # æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦ä¸Žé—®é¢˜å’Œåˆ†ç±»ç›¸å…³
        if any(word in answer_lower for word in question_lower.split()):
            relevance_score = min(5, relevance_score + 1)
    scores['relevance'] = relevance_score
    
    # æœ‰ç”¨æ€§è¯„åˆ†
    helpfulness_score = random.randint(*base_range)
    if any(word in answer_lower for word in ['å»ºè®®', 'æ–¹æ³•', 'è§£å†³', 'å¸®åŠ©', 'æŒ‡å¯¼']):
        helpfulness_score = min(5, helpfulness_score + 1)
    scores['helpfulness'] = helpfulness_score
    
    # ç”Ÿæˆè¯„åˆ†ç†ç”±
    avg_score = sum(scores.values()) / len(scores)
    if avg_score >= 4.0:
        reason_prefix = "ç­”æ¡ˆè´¨é‡ä¼˜ç§€ï¼š"
    elif avg_score >= 3.0:
        reason_prefix = "ç­”æ¡ˆè´¨é‡è‰¯å¥½ï¼š"
    else:
        reason_prefix = "ç­”æ¡ˆè´¨é‡ä¸€èˆ¬ï¼š"
    
    # å…·ä½“ç†ç”±åˆ†æž
    strong_points = []
    weak_points = []
    
    for dim, score in scores.items():
        if score >= 4:
            strong_points.append(SCORING_DIMENSIONS[dim])
        elif score <= 2:
            weak_points.append(SCORING_DIMENSIONS[dim])
    
    reason_parts = [reason_prefix]
    if strong_points:
        reason_parts.append(f"{','.join(strong_points)}è¡¨çŽ°çªå‡º")
    if weak_points:
        reason_parts.append(f"{','.join(weak_points)}æœ‰å¾…æ”¹è¿›")
    
    reason = "ï¼Œ".join(reason_parts) + "ã€‚"
    
    return scores, reason

def generate_multi_model_scores(question, our_answer, doubao_answer, xiaotian_answer, classification):
    """ç”Ÿæˆå¤šæ¨¡åž‹è¯„åˆ†ç»“æžœ"""
    results = []
    
    # è¯„åˆ†æ•°æ®ç»“æž„ï¼š[æ¨¡åž‹å, ç­”æ¡ˆå†…å®¹, æ¨¡åž‹ç±»åž‹]
    models_data = [
        (MODEL_NAMES['our_ai'], our_answer, 'our_ai'),
        (MODEL_NAMES['doubao'], doubao_answer, 'doubao'), 
        (MODEL_NAMES['xiaotian'], xiaotian_answer, 'xiaotian')
    ]
    
    for model_name, answer, model_type in models_data:
        # ç”Ÿæˆè¯¥æ¨¡åž‹çš„è¯„åˆ†
        scores, reason = analyze_answer_quality(question, answer, classification, model_type)
        
        # æž„é€ è¿”å›žæ ¼å¼
        model_result = {
            "æ¨¡åž‹åç§°": model_name,
            "å‡†ç¡®æ€§": scores['accuracy'],
            "å®Œæ•´æ€§": scores['completeness'],
            "æ¸…æ™°åº¦": scores['clarity'],
            "ç›¸å…³æ€§": scores['relevance'],
            "æœ‰ç”¨æ€§": scores['helpfulness'],
            "ç†ç”±": reason
        }
        
        results.append(model_result)
    
    return results

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æŽ¥å£"""
    return jsonify({
        'status': 'healthy',
        'service': 'mock-score-api',
        'version': '1.0.0',
        'timestamp': time.time(),
        'supported_models': list(MODEL_NAMES.values()),
        'scoring_dimensions': list(SCORING_DIMENSIONS.values())
    })

@app.route('/score', methods=['POST'])
def score_answers():
    """å¤šæ¨¡åž‹ç­”æ¡ˆè¯„åˆ†æŽ¥å£ - æŒ‰ç…§ç”¨æˆ·æŒ‡å®šçš„æ ¼å¼"""
    try:
        # æ¨¡æ‹ŸAPIå»¶è¿Ÿ
        time.sleep(random.uniform(0.8, 2.0))
        
        data = request.get_json()
        if not data:
            return jsonify({
                'error': 'Invalid JSON data'
            }), 400
        
        # æ£€æŸ¥inputså­—æ®µ
        inputs = data.get('inputs')
        if not inputs:
            return jsonify({
                'error': 'Missing required field: inputs'
            }), 400
        
        # æ£€æŸ¥å¿…éœ€çš„è¾“å…¥å­—æ®µ
        question = inputs.get('question')
        our_answer = inputs.get('our_answer', '')
        doubao_answer = inputs.get('doubao_answer', '')
        xiaotian_answer = inputs.get('xiaotian_answer', '')
        classification = inputs.get('classification', '')
        
        if not question:
            return jsonify({
                'error': 'Missing required field: inputs.question'
            }), 400
        
        # éªŒè¯APIå¯†é’¥
        api_key = request.headers.get('X-API-Key', '')
        if not api_key:
            return jsonify({
                'error': 'Missing API key'
            }), 401
        
        # æ¨¡æ‹Ÿå¶å°”çš„æœåŠ¡é”™è¯¯ï¼ˆ5%æ¦‚çŽ‡ï¼‰
        if random.random() < 0.05:
            return jsonify({
                'error': 'Internal server error'
            }), 500
        
        # æ¨¡æ‹Ÿå¶å°”çš„é€ŸçŽ‡é™åˆ¶ï¼ˆ2%æ¦‚çŽ‡ï¼‰
        if random.random() < 0.02:
            return jsonify({
                'error': 'Rate limit exceeded'
            }), 429
        
        # ç”Ÿæˆè¯„åˆ†ç»“æžœ
        start_time = time.time()
        score_results = generate_multi_model_scores(
            question, our_answer, doubao_answer, xiaotian_answer, classification
        )
        
        # æŒ‰ç…§ç”¨æˆ·æŒ‡å®šçš„æ ¼å¼è¿”å›ž
        response_data = {
            "data": {
                "outputs": {
                    "text": json.dumps(score_results, ensure_ascii=False, indent=2)
                }
            },
            "processing_time": round((time.time() - start_time) * 1000, 2),
            "timestamp": datetime.now().isoformat()
        }
        
        return jsonify(response_data)
        
    except Exception as e:
        return jsonify({
            'error': f'Scoring failed: {str(e)}'
        }), 500

@app.route('/stats', methods=['GET'])
def get_stats():
    """èŽ·å–APIç»Ÿè®¡ä¿¡æ¯"""
    return jsonify({
        'total_requests': random.randint(500, 2000),
        'success_rate': round(random.uniform(0.95, 0.99), 3),
        'average_response_time': round(random.uniform(800, 1500), 2),
        'models_supported': len(MODEL_NAMES),
        'dimensions_count': len(SCORING_DIMENSIONS),
        'score_distribution': {
            '5åˆ†': random.randint(15, 30),
            '4åˆ†': random.randint(25, 40), 
            '3åˆ†': random.randint(20, 35),
            '2åˆ†': random.randint(10, 20),
            '1åˆ†': random.randint(5, 15)
        },
        'models': list(MODEL_NAMES.values()),
        'dimensions': list(SCORING_DIMENSIONS.values()),
        'uptime': f"{random.randint(20, 100)} days"
    })

@app.route('/test', methods=['POST'])
def test_scoring():
    """æµ‹è¯•æŽ¥å£ï¼Œè¿”å›žæ ¼å¼åŒ–çš„å“åº”"""
    data = request.get_json() or {}
    
    test_result = generate_multi_model_scores(
        question="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•é—®é¢˜",
        our_answer="è¿™æ˜¯åŽŸå§‹æ¨¡åž‹çš„å›žç­”",
        doubao_answer="è¿™æ˜¯è±†åŒ…æ¨¡åž‹çš„å›žç­”", 
        xiaotian_answer="è¿™æ˜¯å°å¤©æ¨¡åž‹çš„å›žç­”",
        classification="æŠ€æœ¯é—®é¢˜"
    )
    
    return jsonify({
        "data": {
            "outputs": {
                "text": json.dumps(test_result, ensure_ascii=False, indent=2)
            }
        },
        "message": "æµ‹è¯•æˆåŠŸ"
    })

def find_available_port(start_port=8004, max_attempts=10):
    """æŸ¥æ‰¾å¯ç”¨ç«¯å£"""
    for port in range(start_port, start_port + max_attempts):
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                s.bind(('localhost', port))
                return port
        except OSError:
            continue
    
    raise RuntimeError(f"æ— æ³•æ‰¾åˆ°å¯ç”¨ç«¯å£ï¼ˆå°è¯•èŒƒå›´: {start_port}-{start_port + max_attempts - 1}ï¼‰")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Mockè¯„åˆ†APIæœåŠ¡å™¨')
    parser.add_argument('--port', type=int, default=8004, help='æŒ‡å®šç«¯å£å·ï¼ˆé»˜è®¤8004ï¼‰')
    parser.add_argument('--auto-port', action='store_true', help='è‡ªåŠ¨æŸ¥æ‰¾å¯ç”¨ç«¯å£')
    args = parser.parse_args()
    
    # ç¡®å®šä½¿ç”¨çš„ç«¯å£
    if args.auto_port:
        try:
            port = find_available_port(args.port)
            print(f"ðŸ” è‡ªåŠ¨æ‰¾åˆ°å¯ç”¨ç«¯å£: {port}")
        except RuntimeError as e:
            print(f"âŒ {e}")
            exit(1)
    else:
        port = args.port
        # æ£€æŸ¥ç«¯å£æ˜¯å¦å¯ç”¨
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                s.bind(('localhost', port))
        except OSError:
            print(f"âŒ ç«¯å£ {port} å·²è¢«å ç”¨")
            print("ðŸ’¡ è§£å†³æ–¹æ¡ˆ:")
            print(f"   1. ä½¿ç”¨å…¶ä»–ç«¯å£: python {__file__} --port 8005")
            print(f"   2. è‡ªåŠ¨æŸ¥æ‰¾ç«¯å£: python {__file__} --auto-port")
            print(f"   3. åœæ­¢å ç”¨ç¨‹åº: sudo lsof -i :{port}")
            exit(1)
    
    print("ðŸ¤– å¯åŠ¨Mockè¯„åˆ†APIæœåŠ¡å™¨...")
    print(f"ðŸ“ åœ°å€: http://localhost:{port}")
    print(f"ðŸ”— å¥åº·æ£€æŸ¥: http://localhost:{port}/health")
    print(f"ðŸ”— è¯„åˆ†æŽ¥å£: POST http://localhost:{port}/score")
    print(f"ðŸ“Š ç»Ÿè®¡æŽ¥å£: http://localhost:{port}/stats")
    print(f"ðŸ§ª æµ‹è¯•æŽ¥å£: POST http://localhost:{port}/test")
    print("-" * 60)
    print("ðŸ“ POSTæ•°æ®æ ¼å¼ï¼ˆæŒ‰ç…§æ‚¨çš„éœ€æ±‚ï¼‰:")
    print("""   {
       "inputs": {
           "question": "ç”¨æˆ·é—®é¢˜æ–‡æœ¬",
           "our_answer": "åŽŸå§‹æ¨¡åž‹ç­”æ¡ˆ",
           "doubao_answer": "è±†åŒ…æ¨¡åž‹ç­”æ¡ˆ", 
           "xiaotian_answer": "å°å¤©æ¨¡åž‹ç­”æ¡ˆ",
           "classification": "é—®é¢˜åˆ†ç±»"
       }
   }""")
    print("ðŸ”‘ è®¤è¯: X-API-Key: your-api-key")
    print("-" * 60)
    print("ðŸ“‹ æ”¯æŒçš„æ¨¡åž‹:")
    for key, name in MODEL_NAMES.items():
        print(f"   {key}: {name}")
    print("ðŸ“‹ è¯„åˆ†ç»´åº¦:")
    for key, name in SCORING_DIMENSIONS.items():
        print(f"   {key}: {name}")
    print("-" * 60)
    
    try:
        app.run(host='0.0.0.0', port=port, debug=False, use_reloader=False)
    except KeyboardInterrupt:
        print(f"\nðŸ›‘ Mockè¯„åˆ†APIæœåŠ¡å™¨å·²åœæ­¢")
    except OSError as e:
        if "Address already in use" in str(e):
            print(f"âŒ ç«¯å£ {port} å·²è¢«å ç”¨")
            if args.auto_port:
                try:
                    new_port = find_available_port(port + 1)
                    print(f"ðŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°ç«¯å£ {new_port}")
                    app.run(host='0.0.0.0', port=new_port, debug=False, use_reloader=False)
                except RuntimeError as re:
                    print(f"âŒ {re}")
                    exit(1)
            else:
                print("ðŸ’¡ è§£å†³æ–¹æ¡ˆ:")
                print(f"   1. ä½¿ç”¨å…¶ä»–ç«¯å£: python {__file__} --port {port + 1}")
                print(f"   2. è‡ªåŠ¨æŸ¥æ‰¾ç«¯å£: python {__file__} --auto-port")
                print(f"   3. åœæ­¢å ç”¨ç¨‹åº: pkill -f mock_score_api")
                exit(1)
        else:
            raise

if __name__ == '__main__':
    main() 