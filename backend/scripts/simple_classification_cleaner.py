#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆåˆ†ç±»æ•°æ®æ¸…ç†å·¥å…·
ç›´æ¥ä½¿ç”¨SQLAlchemyè¿æ¥æ•°æ®åº“ï¼Œé¿å…Flaskåº”ç”¨ä¾èµ–é—®é¢˜
"""

import os
import sys
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

# æ ‡å‡†16ç§åˆ†ç±»
STANDARD_CLASSIFICATIONS = [
    'æŠ€æœ¯é—®é¢˜', 'äº§å“ä½¿ç”¨', 'ä¸šåŠ¡å’¨è¯¢', 'åŠŸèƒ½å»ºè®®', 'æ•…éšœæ’æŸ¥',
    'å…¶ä»–', 'å·¥ç¨‹é—®é¢˜', 'ç§‘å­¦é—®é¢˜', 'æ•™è‚²é—®é¢˜', 'ç»æµé—®é¢˜',
    'è´¦æˆ·ç®¡ç†', 'ç³»ç»Ÿä¼˜åŒ–', 'å®‰å…¨è®¾ç½®', 'æ•°æ®åˆ†æ',
    'ç”¨æˆ·ä½“éªŒ', 'æ€§èƒ½ä¼˜åŒ–'
]

def get_database_url():
    """è·å–æ•°æ®åº“è¿æ¥URL"""
    # ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶è·å–æ•°æ®åº“URL
    db_url = os.getenv('DATABASE_URL')
    if not db_url:
        # é»˜è®¤SQLiteæ•°æ®åº“è·¯å¾„
        db_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'instance', 'ai_qa_platform.db')
        db_url = f'sqlite:///{db_path}'
    return db_url

def analyze_classifications():
    """åˆ†ææ•°æ®åº“ä¸­çš„åˆ†ç±»æ•°æ®"""
    print("ğŸ” åˆ†ææ•°æ®åº“ä¸­çš„åˆ†ç±»æ•°æ®...")
    
    db_url = get_database_url()
    engine = create_engine(db_url)
    Session = sessionmaker(bind=engine)
    session = Session()
    
    try:
        # æŸ¥è¯¢æ‰€æœ‰åˆ†ç±»åŠå…¶æ•°é‡
        query = text("""
            SELECT classification, COUNT(*) as count 
            FROM questions 
            WHERE classification IS NOT NULL AND classification != '' 
            GROUP BY classification 
            ORDER BY count DESC
        """)
        
        result = session.execute(query)
        classifications = result.fetchall()
        
        print(f"\nğŸ“Š æ•°æ®åº“ä¸­çš„åˆ†ç±»æ€»æ•°: {len(classifications)}")
        print("=" * 60)
        
        standard_classifications = []
        invalid_classifications = []
        
        for row in classifications:
            classification = row[0]
            count = row[1]
            
            if classification in STANDARD_CLASSIFICATIONS:
                standard_classifications.append((classification, count))
            else:
                invalid_classifications.append((classification, count))
        
        print(f"âœ… æ ‡å‡†åˆ†ç±» ({len(standard_classifications)}ä¸ª):")
        for classification, count in standard_classifications:
            print(f"   {classification}: {count}ä¸ªé—®é¢˜")
        
        print(f"\nâŒ éæ ‡å‡†åˆ†ç±» ({len(invalid_classifications)}ä¸ª):")
        total_invalid_questions = 0
        for classification, count in invalid_classifications:
            print(f"   {classification}: {count}ä¸ªé—®é¢˜")
            total_invalid_questions += count
        
        print(f"\nğŸ“ˆ ç»Ÿè®¡æ‘˜è¦:")
        print(f"   - æ ‡å‡†åˆ†ç±»æ•°é‡: {len(standard_classifications)}")
        print(f"   - éæ ‡å‡†åˆ†ç±»æ•°é‡: {len(invalid_classifications)}")
        print(f"   - éœ€è¦é‡æ–°åˆ†ç±»çš„é—®é¢˜æ•°: {total_invalid_questions}")
        
        return invalid_classifications
        
    finally:
        session.close()

def map_invalid_to_standard(invalid_classification):
    """å°†æ— æ•ˆåˆ†ç±»æ˜ å°„åˆ°æ ‡å‡†åˆ†ç±»"""
    # å®šä¹‰æ˜ å°„è§„åˆ™
    mapping_rules = {
        # æŠ€æœ¯ç›¸å…³
        'æŠ€æœ¯é—®é¢˜ç±»': 'æŠ€æœ¯é—®é¢˜',
        'æŠ€æœ¯æ”¯æŒ': 'æŠ€æœ¯é—®é¢˜',
        'å¼€å‘é—®é¢˜': 'æŠ€æœ¯é—®é¢˜',
        'ç¼–ç¨‹é—®é¢˜': 'æŠ€æœ¯é—®é¢˜',
        'APIé—®é¢˜': 'æŠ€æœ¯é—®é¢˜',
        'é›†æˆé—®é¢˜': 'æŠ€æœ¯é—®é¢˜',
        
        # äº§å“ä½¿ç”¨ç›¸å…³
        'äº§å“å’¨è¯¢': 'äº§å“ä½¿ç”¨',
        'ä½¿ç”¨æŒ‡å—': 'äº§å“ä½¿ç”¨',
        'æ“ä½œé—®é¢˜': 'äº§å“ä½¿ç”¨',
        'ä½¿ç”¨æ–¹æ³•': 'äº§å“ä½¿ç”¨',
        
        # åŠŸèƒ½ç›¸å…³
        'åŠŸèƒ½å’¨è¯¢': 'åŠŸèƒ½å»ºè®®',
        'æ–°åŠŸèƒ½': 'åŠŸèƒ½å»ºè®®',
        'åŠŸèƒ½éœ€æ±‚': 'åŠŸèƒ½å»ºè®®',
        'æ”¹è¿›å»ºè®®': 'åŠŸèƒ½å»ºè®®',
        
        # æ•…éšœç›¸å…³
        'æ•…éšœé—®é¢˜': 'æ•…éšœæ’æŸ¥',
        'é”™è¯¯æ’æŸ¥': 'æ•…éšœæ’æŸ¥',
        'é—®é¢˜æ’æŸ¥': 'æ•…éšœæ’æŸ¥',
        'å¼‚å¸¸å¤„ç†': 'æ•…éšœæ’æŸ¥',
        
        # ä¸šåŠ¡ç›¸å…³
        'å•†åŠ¡å’¨è¯¢': 'ä¸šåŠ¡å’¨è¯¢',
        'åˆä½œå’¨è¯¢': 'ä¸šåŠ¡å’¨è¯¢',
        'å•†ä¸šé—®é¢˜': 'ä¸šåŠ¡å’¨è¯¢',
        
        # è´¦æˆ·ç›¸å…³
        'è´¦å·é—®é¢˜': 'è´¦æˆ·ç®¡ç†',
        'ç™»å½•é—®é¢˜': 'è´¦æˆ·ç®¡ç†',
        'æƒé™é—®é¢˜': 'è´¦æˆ·ç®¡ç†',
        
        # ç³»ç»Ÿç›¸å…³
        'ç³»ç»Ÿé—®é¢˜': 'ç³»ç»Ÿä¼˜åŒ–',
        'æ€§èƒ½é—®é¢˜': 'æ€§èƒ½ä¼˜åŒ–',
        'ä¼˜åŒ–å»ºè®®': 'æ€§èƒ½ä¼˜åŒ–',
        
        # å®‰å…¨ç›¸å…³
        'å®‰å…¨é—®é¢˜': 'å®‰å…¨è®¾ç½®',
        'æƒé™è®¾ç½®': 'å®‰å…¨è®¾ç½®',
        
        # æ•°æ®ç›¸å…³
        'æ•°æ®é—®é¢˜': 'æ•°æ®åˆ†æ',
        'ç»Ÿè®¡é—®é¢˜': 'æ•°æ®åˆ†æ',
        'æŠ¥è¡¨é—®é¢˜': 'æ•°æ®åˆ†æ',
        
        # ç”¨æˆ·ä½“éªŒç›¸å…³
        'ç•Œé¢é—®é¢˜': 'ç”¨æˆ·ä½“éªŒ',
        'UIé—®é¢˜': 'ç”¨æˆ·ä½“éªŒ',
        'äº¤äº’é—®é¢˜': 'ç”¨æˆ·ä½“éªŒ',
    }
    
    # é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…
    if invalid_classification in mapping_rules:
        return mapping_rules[invalid_classification]
    
    # åŸºäºå…³é”®è¯åŒ¹é…
    if any(keyword in invalid_classification for keyword in ['æŠ€æœ¯', 'å¼€å‘', 'API', 'ä»£ç ', 'ç¼–ç¨‹']):
        return 'æŠ€æœ¯é—®é¢˜'
    elif any(keyword in invalid_classification for keyword in ['äº§å“', 'ä½¿ç”¨', 'æ“ä½œ']):
        return 'äº§å“ä½¿ç”¨'
    elif any(keyword in invalid_classification for keyword in ['ä¸šåŠ¡', 'å•†åŠ¡', 'åˆä½œ', 'å•†ä¸š']):
        return 'ä¸šåŠ¡å’¨è¯¢'
    elif any(keyword in invalid_classification for keyword in ['å»ºè®®', 'éœ€æ±‚', 'æ”¹è¿›']):
        return 'åŠŸèƒ½å»ºè®®'
    elif any(keyword in invalid_classification for keyword in ['æ•…éšœ', 'é”™è¯¯', 'å¼‚å¸¸']):
        return 'æ•…éšœæ’æŸ¥'
    elif any(keyword in invalid_classification for keyword in ['è´¦æˆ·', 'è´¦å·', 'ç™»å½•', 'æƒé™']):
        return 'è´¦æˆ·ç®¡ç†'
    elif any(keyword in invalid_classification for keyword in ['ç³»ç»Ÿ', 'é…ç½®']):
        return 'ç³»ç»Ÿä¼˜åŒ–'
    elif any(keyword in invalid_classification for keyword in ['å®‰å…¨', 'é˜²æŠ¤']):
        return 'å®‰å…¨è®¾ç½®'
    elif any(keyword in invalid_classification for keyword in ['æ•°æ®', 'ç»Ÿè®¡', 'åˆ†æ', 'æŠ¥è¡¨']):
        return 'æ•°æ®åˆ†æ'
    elif any(keyword in invalid_classification for keyword in ['ä½“éªŒ', 'ç•Œé¢', 'UI', 'äº¤äº’']):
        return 'ç”¨æˆ·ä½“éªŒ'
    elif any(keyword in invalid_classification for keyword in ['æ€§èƒ½', 'é€Ÿåº¦', 'æ•ˆç‡', 'ä¼˜åŒ–']):
        return 'æ€§èƒ½ä¼˜åŒ–'
    elif any(keyword in invalid_classification for keyword in ['æ•™è‚²', 'å­¦ä¹ ', 'åŸ¹è®­']):
        return 'æ•™è‚²é—®é¢˜'
    elif any(keyword in invalid_classification for keyword in ['å·¥ç¨‹', 'é¡¹ç›®']):
        return 'å·¥ç¨‹é—®é¢˜'
    elif any(keyword in invalid_classification for keyword in ['ç§‘å­¦', 'ç ”ç©¶', 'å­¦æœ¯']):
        return 'ç§‘å­¦é—®é¢˜'
    elif any(keyword in invalid_classification for keyword in ['ç»æµ', 'è´¹ç”¨', 'ä»·æ ¼', 'æˆæœ¬']):
        return 'ç»æµé—®é¢˜'
    else:
        return 'å…¶ä»–'

def clean_invalid_classifications(dry_run=True):
    """æ¸…ç†æ— æ•ˆåˆ†ç±»"""
    print(f"\nğŸ§¹ {'æ¨¡æ‹Ÿ' if dry_run else 'æ‰§è¡Œ'}æ¸…ç†æ— æ•ˆåˆ†ç±»...")
    
    db_url = get_database_url()
    engine = create_engine(db_url)
    Session = sessionmaker(bind=engine)
    session = Session()
    
    try:
        # è·å–æ‰€æœ‰éæ ‡å‡†åˆ†ç±»çš„é—®é¢˜
        placeholders = ','.join(['?' for _ in STANDARD_CLASSIFICATIONS])
        query = text(f"""
            SELECT id, classification 
            FROM questions 
            WHERE classification IS NOT NULL 
            AND classification != '' 
            AND classification NOT IN ({placeholders})
        """)
        
        result = session.execute(query, STANDARD_CLASSIFICATIONS)
        invalid_questions = result.fetchall()
        
        if not invalid_questions:
            print("âœ… æ²¡æœ‰å‘ç°éœ€è¦æ¸…ç†çš„æ— æ•ˆåˆ†ç±»")
            return
        
        print(f"ğŸ“ æ‰¾åˆ° {len(invalid_questions)} ä¸ªéœ€è¦é‡æ–°åˆ†ç±»çš„é—®é¢˜")
        
        # ç»Ÿè®¡æ˜ å°„ç»“æœ
        mapping_stats = {}
        updates = []
        
        for question_id, old_classification in invalid_questions:
            new_classification = map_invalid_to_standard(old_classification)
            
            if old_classification not in mapping_stats:
                mapping_stats[old_classification] = {'count': 0, 'new_classification': new_classification}
            mapping_stats[old_classification]['count'] += 1
            
            updates.append((new_classification, question_id))
        
        # æ˜¾ç¤ºæ˜ å°„ç»Ÿè®¡
        print("\nğŸ“‹ åˆ†ç±»æ˜ å°„ç»Ÿè®¡:")
        print("-" * 80)
        for old_classification, stats in mapping_stats.items():
            print(f"   {old_classification} ({stats['count']}ä¸ª) â†’ {stats['new_classification']}")
        
        if not dry_run:
            try:
                # æ‰¹é‡æ›´æ–°
                update_query = text("UPDATE questions SET classification = ? WHERE id = ?")
                session.execute(update_query, updates)
                session.commit()
                print(f"\nâœ… æˆåŠŸæ›´æ–°äº† {len(invalid_questions)} ä¸ªé—®é¢˜çš„åˆ†ç±»")
            except Exception as e:
                session.rollback()
                print(f"\nâŒ æ›´æ–°å¤±è´¥: {str(e)}")
        else:
            print(f"\nğŸ’¡ è¿™æ˜¯æ¨¡æ‹Ÿè¿è¡Œï¼Œå®é™…æ•°æ®æœªè¢«ä¿®æ”¹")
            print("   å¦‚éœ€æ‰§è¡Œå®é™…æ¸…ç†ï¼Œè¯·è¿è¡Œ: python3 simple_classification_cleaner.py --execute")
            
    finally:
        session.close()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹åˆ†ç±»æ•°æ®æ¸…ç†å·¥å…·")
    print("=" * 60)
    
    # åˆ†æå½“å‰åˆ†ç±»çŠ¶æ€
    invalid_classifications = analyze_classifications()
    
    if not invalid_classifications:
        print("\nâœ… æ•°æ®åº“ä¸­çš„åˆ†ç±»æ•°æ®å·²ç»æ˜¯æ ‡å‡†çš„ï¼Œæ— éœ€æ¸…ç†")
        return
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    dry_run = '--execute' not in sys.argv
    
    if dry_run:
        print(f"\nâš ï¸  è¿™æ˜¯æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼")
        print("   å¦‚éœ€æ‰§è¡Œå®é™…æ¸…ç†ï¼Œè¯·æ·»åŠ  --execute å‚æ•°")
    
    # æ‰§è¡Œæ¸…ç†
    clean_invalid_classifications(dry_run=dry_run)
    
    if not dry_run:
        print("\nğŸ”„ é‡æ–°åˆ†ææ¸…ç†åçš„åˆ†ç±»æ•°æ®...")
        analyze_classifications()

if __name__ == '__main__':
    main()
