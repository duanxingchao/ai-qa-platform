#!/usr/bin/env python3
"""
æ¸…ç†æ•°æ®åº“ä¸­çš„æ— æ•ˆåˆ†ç±»æ•°æ®
å°†éæ ‡å‡†åˆ†ç±»çš„é—®é¢˜é‡æ–°åˆ†ç±»ä¸ºæ ‡å‡†çš„16ç§åˆ†ç±»ä¹‹ä¸€
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app import create_app
from app.models.question import Question
from app.utils.database import db
import random

# Mockåˆ†ç±»APIå®šä¹‰çš„æ ‡å‡†16ç§åˆ†ç±»
STANDARD_CLASSIFICATIONS = [
    'æŠ€æœ¯é—®é¢˜', 'äº§å“ä½¿ç”¨', 'ä¸šåŠ¡å’¨è¯¢', 'åŠŸèƒ½å»ºè®®', 'æ•…éšœæ’æŸ¥',
    'å…¶ä»–', 'å·¥ç¨‹é—®é¢˜', 'ç§‘å­¦é—®é¢˜', 'æ•™è‚²é—®é¢˜', 'ç»æµé—®é¢˜',
    'è´¦æˆ·ç®¡ç†', 'ç³»ç»Ÿä¼˜åŒ–', 'å®‰å…¨è®¾ç½®', 'æ•°æ®åˆ†æ',
    'ç”¨æˆ·ä½“éªŒ', 'æ€§èƒ½ä¼˜åŒ–'
]

def analyze_classifications():
    """åˆ†ææ•°æ®åº“ä¸­çš„åˆ†ç±»æ•°æ®"""
    print("ğŸ” åˆ†ææ•°æ®åº“ä¸­çš„åˆ†ç±»æ•°æ®...")
    
    # è·å–æ‰€æœ‰ä¸åŒçš„åˆ†ç±»åŠå…¶æ•°é‡
    classifications = db.session.query(
        Question.classification,
        db.func.count(Question.id).label('count')
    ).filter(
        Question.classification.isnot(None),
        Question.classification != ''
    ).group_by(Question.classification).order_by(db.func.count(Question.id).desc()).all()
    
    print(f"\nğŸ“Š æ•°æ®åº“ä¸­çš„åˆ†ç±»æ€»æ•°: {len(classifications)}")
    print("=" * 60)
    
    standard_classifications = []
    invalid_classifications = []
    
    for classification, count in classifications:
        if classification in STANDARD_CLASSIFICATIONS:
            standard_classifications.append((classification, count))
        else:
            invalid_classifications.append((classification, count))
    
    print(f"âœ… æ ‡å‡†åˆ†ç±» ({len(standard_classifications)}ä¸ª):")
    for classification, count in standard_classifications:
        print(f"   {classification}: {count}ä¸ªé—®é¢˜")
    
    print(f"\nâŒ éæ ‡å‡†åˆ†ç±» ({len(invalid_classifications)}ä¸ª):")
    total_invalid_questions = 0
    for classification, count in invalid_classifications:
        print(f"   {classification}: {count}ä¸ªé—®é¢˜")
        total_invalid_questions += count
    
    print(f"\nğŸ“ˆ ç»Ÿè®¡æ‘˜è¦:")
    print(f"   - æ ‡å‡†åˆ†ç±»æ•°é‡: {len(standard_classifications)}")
    print(f"   - éæ ‡å‡†åˆ†ç±»æ•°é‡: {len(invalid_classifications)}")
    print(f"   - éœ€è¦é‡æ–°åˆ†ç±»çš„é—®é¢˜æ•°: {total_invalid_questions}")
    
    return invalid_classifications

def map_invalid_to_standard(invalid_classification):
    """å°†æ— æ•ˆåˆ†ç±»æ˜ å°„åˆ°æ ‡å‡†åˆ†ç±»"""
    # å®šä¹‰æ˜ å°„è§„åˆ™
    mapping_rules = {
        # æŠ€æœ¯ç›¸å…³
        'æŠ€æœ¯é—®é¢˜ç±»': 'æŠ€æœ¯é—®é¢˜',
        'æŠ€æœ¯æ”¯æŒ': 'æŠ€æœ¯é—®é¢˜',
        'å¼€å‘é—®é¢˜': 'æŠ€æœ¯é—®é¢˜',
        'ç¼–ç¨‹é—®é¢˜': 'æŠ€æœ¯é—®é¢˜',
        'APIé—®é¢˜': 'æŠ€æœ¯é—®é¢˜',
        'é›†æˆé—®é¢˜': 'æŠ€æœ¯é—®é¢˜',
        
        # äº§å“ä½¿ç”¨ç›¸å…³
        'äº§å“å’¨è¯¢': 'äº§å“ä½¿ç”¨',
        'ä½¿ç”¨æŒ‡å—': 'äº§å“ä½¿ç”¨',
        'æ“ä½œé—®é¢˜': 'äº§å“ä½¿ç”¨',
        'ä½¿ç”¨æ–¹æ³•': 'äº§å“ä½¿ç”¨',
        
        # åŠŸèƒ½ç›¸å…³
        'åŠŸèƒ½å’¨è¯¢': 'åŠŸèƒ½å»ºè®®',
        'æ–°åŠŸèƒ½': 'åŠŸèƒ½å»ºè®®',
        'åŠŸèƒ½éœ€æ±‚': 'åŠŸèƒ½å»ºè®®',
        'æ”¹è¿›å»ºè®®': 'åŠŸèƒ½å»ºè®®',
        
        # æ•…éšœç›¸å…³
        'æ•…éšœé—®é¢˜': 'æ•…éšœæ’æŸ¥',
        'é”™è¯¯æ’æŸ¥': 'æ•…éšœæ’æŸ¥',
        'é—®é¢˜æ’æŸ¥': 'æ•…éšœæ’æŸ¥',
        'å¼‚å¸¸å¤„ç†': 'æ•…éšœæ’æŸ¥',
        
        # ä¸šåŠ¡ç›¸å…³
        'å•†åŠ¡å’¨è¯¢': 'ä¸šåŠ¡å’¨è¯¢',
        'åˆä½œå’¨è¯¢': 'ä¸šåŠ¡å’¨è¯¢',
        'å•†ä¸šé—®é¢˜': 'ä¸šåŠ¡å’¨è¯¢',
        
        # è´¦æˆ·ç›¸å…³
        'è´¦å·é—®é¢˜': 'è´¦æˆ·ç®¡ç†',
        'ç™»å½•é—®é¢˜': 'è´¦æˆ·ç®¡ç†',
        'æƒé™é—®é¢˜': 'è´¦æˆ·ç®¡ç†',
        
        # ç³»ç»Ÿç›¸å…³
        'ç³»ç»Ÿé—®é¢˜': 'ç³»ç»Ÿä¼˜åŒ–',
        'æ€§èƒ½é—®é¢˜': 'æ€§èƒ½ä¼˜åŒ–',
        'ä¼˜åŒ–å»ºè®®': 'æ€§èƒ½ä¼˜åŒ–',
        
        # å®‰å…¨ç›¸å…³
        'å®‰å…¨é—®é¢˜': 'å®‰å…¨è®¾ç½®',
        'æƒé™è®¾ç½®': 'å®‰å…¨è®¾ç½®',
        
        # æ•°æ®ç›¸å…³
        'æ•°æ®é—®é¢˜': 'æ•°æ®åˆ†æ',
        'ç»Ÿè®¡é—®é¢˜': 'æ•°æ®åˆ†æ',
        'æŠ¥è¡¨é—®é¢˜': 'æ•°æ®åˆ†æ',
        
        # ç”¨æˆ·ä½“éªŒç›¸å…³
        'ç•Œé¢é—®é¢˜': 'ç”¨æˆ·ä½“éªŒ',
        'UIé—®é¢˜': 'ç”¨æˆ·ä½“éªŒ',
        'äº¤äº’é—®é¢˜': 'ç”¨æˆ·ä½“éªŒ',
        
        # æ•™è‚²ç›¸å…³
        'å­¦ä¹ é—®é¢˜': 'æ•™è‚²é—®é¢˜',
        'åŸ¹è®­é—®é¢˜': 'æ•™è‚²é—®é¢˜',
        
        # å·¥ç¨‹ç›¸å…³
        'å·¥ç¨‹å’¨è¯¢': 'å·¥ç¨‹é—®é¢˜',
        'é¡¹ç›®é—®é¢˜': 'å·¥ç¨‹é—®é¢˜',
        
        # ç§‘å­¦ç›¸å…³
        'ç ”ç©¶é—®é¢˜': 'ç§‘å­¦é—®é¢˜',
        'å­¦æœ¯é—®é¢˜': 'ç§‘å­¦é—®é¢˜',
        
        # ç»æµç›¸å…³
        'è´¹ç”¨é—®é¢˜': 'ç»æµé—®é¢˜',
        'ä»·æ ¼å’¨è¯¢': 'ç»æµé—®é¢˜',
        'æˆæœ¬é—®é¢˜': 'ç»æµé—®é¢˜'
    }
    
    # é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…
    if invalid_classification in mapping_rules:
        return mapping_rules[invalid_classification]
    
    # ç„¶åå°è¯•æ¨¡ç³ŠåŒ¹é…
    invalid_lower = invalid_classification.lower()
    for key, value in mapping_rules.items():
        if key.lower() in invalid_lower or invalid_lower in key.lower():
            return value
    
    # åŸºäºå…³é”®è¯åŒ¹é…
    if any(keyword in invalid_classification for keyword in ['æŠ€æœ¯', 'å¼€å‘', 'API', 'ä»£ç ', 'ç¼–ç¨‹']):
        return 'æŠ€æœ¯é—®é¢˜'
    elif any(keyword in invalid_classification for keyword in ['äº§å“', 'ä½¿ç”¨', 'æ“ä½œ', 'åŠŸèƒ½']):
        return 'äº§å“ä½¿ç”¨'
    elif any(keyword in invalid_classification for keyword in ['ä¸šåŠ¡', 'å•†åŠ¡', 'åˆä½œ', 'å•†ä¸š']):
        return 'ä¸šåŠ¡å’¨è¯¢'
    elif any(keyword in invalid_classification for keyword in ['å»ºè®®', 'éœ€æ±‚', 'æ”¹è¿›', 'ä¼˜åŒ–']):
        return 'åŠŸèƒ½å»ºè®®'
    elif any(keyword in invalid_classification for keyword in ['æ•…éšœ', 'é”™è¯¯', 'å¼‚å¸¸', 'é—®é¢˜']):
        return 'æ•…éšœæ’æŸ¥'
    elif any(keyword in invalid_classification for keyword in ['è´¦æˆ·', 'è´¦å·', 'ç™»å½•', 'æƒé™']):
        return 'è´¦æˆ·ç®¡ç†'
    elif any(keyword in invalid_classification for keyword in ['ç³»ç»Ÿ', 'é…ç½®']):
        return 'ç³»ç»Ÿä¼˜åŒ–'
    elif any(keyword in invalid_classification for keyword in ['å®‰å…¨', 'é˜²æŠ¤']):
        return 'å®‰å…¨è®¾ç½®'
    elif any(keyword in invalid_classification for keyword in ['æ•°æ®', 'ç»Ÿè®¡', 'åˆ†æ', 'æŠ¥è¡¨']):
        return 'æ•°æ®åˆ†æ'
    elif any(keyword in invalid_classification for keyword in ['ä½“éªŒ', 'ç•Œé¢', 'UI', 'äº¤äº’']):
        return 'ç”¨æˆ·ä½“éªŒ'
    elif any(keyword in invalid_classification for keyword in ['æ€§èƒ½', 'é€Ÿåº¦', 'æ•ˆç‡']):
        return 'æ€§èƒ½ä¼˜åŒ–'
    elif any(keyword in invalid_classification for keyword in ['æ•™è‚²', 'å­¦ä¹ ', 'åŸ¹è®­']):
        return 'æ•™è‚²é—®é¢˜'
    elif any(keyword in invalid_classification for keyword in ['å·¥ç¨‹', 'é¡¹ç›®']):
        return 'å·¥ç¨‹é—®é¢˜'
    elif any(keyword in invalid_classification for keyword in ['ç§‘å­¦', 'ç ”ç©¶', 'å­¦æœ¯']):
        return 'ç§‘å­¦é—®é¢˜'
    elif any(keyword in invalid_classification for keyword in ['ç»æµ', 'è´¹ç”¨', 'ä»·æ ¼', 'æˆæœ¬']):
        return 'ç»æµé—®é¢˜'
    else:
        # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œéšæœºåˆ†é…åˆ°ä¸€ä¸ªåˆé€‚çš„åˆ†ç±»
        return 'å…¶ä»–'

def clean_invalid_classifications(dry_run=True):
    """æ¸…ç†æ— æ•ˆåˆ†ç±»"""
    print(f"\nğŸ§¹ {'æ¨¡æ‹Ÿ' if dry_run else 'æ‰§è¡Œ'}æ¸…ç†æ— æ•ˆåˆ†ç±»...")
    
    # è·å–æ‰€æœ‰éæ ‡å‡†åˆ†ç±»çš„é—®é¢˜
    invalid_questions = db.session.query(Question).filter(
        Question.classification.isnot(None),
        Question.classification != '',
        ~Question.classification.in_(STANDARD_CLASSIFICATIONS)
    ).all()
    
    if not invalid_questions:
        print("âœ… æ²¡æœ‰å‘ç°éœ€è¦æ¸…ç†çš„æ— æ•ˆåˆ†ç±»")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(invalid_questions)} ä¸ªéœ€è¦é‡æ–°åˆ†ç±»çš„é—®é¢˜")
    
    # ç»Ÿè®¡æ˜ å°„ç»“æœ
    mapping_stats = {}
    
    for question in invalid_questions:
        old_classification = question.classification
        new_classification = map_invalid_to_standard(old_classification)
        
        if old_classification not in mapping_stats:
            mapping_stats[old_classification] = {'count': 0, 'new_classification': new_classification}
        mapping_stats[old_classification]['count'] += 1
        
        if not dry_run:
            question.classification = new_classification
    
    # æ˜¾ç¤ºæ˜ å°„ç»Ÿè®¡
    print("\nğŸ“‹ åˆ†ç±»æ˜ å°„ç»Ÿè®¡:")
    print("-" * 80)
    for old_classification, stats in mapping_stats.items():
        print(f"   {old_classification} ({stats['count']}ä¸ª) â†’ {stats['new_classification']}")
    
    if not dry_run:
        try:
            db.session.commit()
            print(f"\nâœ… æˆåŠŸæ›´æ–°äº† {len(invalid_questions)} ä¸ªé—®é¢˜çš„åˆ†ç±»")
        except Exception as e:
            db.session.rollback()
            print(f"\nâŒ æ›´æ–°å¤±è´¥: {str(e)}")
    else:
        print(f"\nğŸ’¡ è¿™æ˜¯æ¨¡æ‹Ÿè¿è¡Œï¼Œå®é™…æ•°æ®æœªè¢«ä¿®æ”¹")
        print("   å¦‚éœ€æ‰§è¡Œå®é™…æ¸…ç†ï¼Œè¯·è¿è¡Œ: python clean_invalid_classifications.py --execute")

def main():
    """ä¸»å‡½æ•°"""
    app = create_app()
    
    with app.app_context():
        print("ğŸš€ å¼€å§‹åˆ†ç±»æ•°æ®æ¸…ç†å·¥å…·")
        print("=" * 60)
        
        # åˆ†æå½“å‰åˆ†ç±»çŠ¶æ€
        invalid_classifications = analyze_classifications()
        
        if not invalid_classifications:
            print("\nâœ… æ•°æ®åº“ä¸­çš„åˆ†ç±»æ•°æ®å·²ç»æ˜¯æ ‡å‡†çš„ï¼Œæ— éœ€æ¸…ç†")
            return
        
        # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
        import sys
        dry_run = '--execute' not in sys.argv
        
        if dry_run:
            print(f"\nâš ï¸  è¿™æ˜¯æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼")
            print("   å¦‚éœ€æ‰§è¡Œå®é™…æ¸…ç†ï¼Œè¯·æ·»åŠ  --execute å‚æ•°")
        
        # æ‰§è¡Œæ¸…ç†
        clean_invalid_classifications(dry_run=dry_run)
        
        if not dry_run:
            print("\nğŸ”„ é‡æ–°åˆ†ææ¸…ç†åçš„åˆ†ç±»æ•°æ®...")
            analyze_classifications()

if __name__ == '__main__':
    main()
